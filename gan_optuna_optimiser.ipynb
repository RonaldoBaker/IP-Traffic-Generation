{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71dfc09-55e2-4d52-9d95-fd3cc90c8cd8",
   "metadata": {},
   "source": [
    "# Optimising the GAN to produce flow duration and flow size using Optuna\n",
    "\n",
    "Following three examples:\n",
    "\n",
    "1. https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837\n",
    "This example is a simple example to follow.\n",
    "\n",
    "2. https://github.com/optuna/optuna-examples/blob/main/multi_objective/pytorch_simple.py\n",
    "This example is more complicated but demonstrates how to have multi-objective optimisation, which is key in optimising the GAN, where we need to minimise loss for both neural networks.\n",
    "\n",
    "3. https://gitlab.com/hpo-uq/applications/gan4hep/-/blob/main/gan4hep/train_gan_2angles.py?ref_type=heads\n",
    "This example comes from the HYPPO paper, 'gan4hep' module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e0c4355-74fa-4577-9cd9-0f198d3df65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import optuna\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ec6f6-5ef3-4067-b87d-66b0276d0d32",
   "metadata": {},
   "source": [
    "## Discriminator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f04d43b5-e2d7-46d5-8049-7ca51f189848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Input is 2D, first hidden layer is composed of 256 neurons with ReLU activation\n",
    "            nn.Linear(2, 256), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Have to use dropout to avoid overfitting\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # second and third layers are composed to 128 and 64 neurons, respectively\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # output is composed of a single neuron with sigmoidal activation to represent a probability\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee49249-76f2-4f9b-8803-f6d4c3630004",
   "metadata": {},
   "source": [
    "## Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7990e8e5-a832-4ee7-bbaf-0f45a27adb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92660876-6c93-402c-a7a2-c0ace1f03703",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3ce02bc-0c1f-4c4b-ac37-1acfc41c9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA_LENGTH = 1024\n",
    "\n",
    "def train_data_length(data, length):\n",
    "    return data[:length]\n",
    "    \n",
    "def load_data():\n",
    "    data = torch.load(\"data.pt\")\n",
    "    data = data.to(torch.float32)\n",
    "    train_data = train_data_length(data,TRAINING_DATA_LENGTH)\n",
    "    return train_data\n",
    "    \n",
    "print(\"Done\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a89e0403-1680-4896-bc3b-2a6c201b2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_optimise(params, generator, discriminator, trial):\n",
    "    RANDOM_SEED = 77\n",
    "    TRAINING_DATA_LENGTH = 1024\n",
    "\n",
    "    # Device agnostic code\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # loading and moving the training data and models to the GPU if it is available\n",
    "    train_data = load_data()\n",
    "    train_data = train_data.to(device)\n",
    "    train_labels = torch.zeros(size=(TRAINING_DATA_LENGTH, 1))\n",
    "    train_labels = train_labels.to(device)\n",
    "    train_set = [(train_data[i], train_labels[i]) for i in range(TRAINING_DATA_LENGTH)]\n",
    "    train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"], shuffle=True, drop_last = True)\n",
    "\n",
    "    loss_function = nn.BCELoss()\n",
    "    discriminator_optimiser = optim.Adam(discriminator.parameters(), lr = params[\"learning_rate\"])\n",
    "    generator_optimiser = optim.Adam(generator.parameters(), lr = params[\"learning_rate\"])\n",
    "\n",
    "    if use_cuda:\n",
    "        discriminator = discriminator.cuda()\n",
    "        generator = generator.cuda()\n",
    "        loss_function = loss_function.cuda()\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(params[\"epochs\"]):\n",
    "        \n",
    "        for n, (real_samples, _) in enumerate(tqdm(train_loader)):\n",
    "            # DATA FOR DISCRIMINATOR\n",
    "            torch.manual_seed(RANDOM_SEED)\n",
    "            real_samples_labels = torch.ones((params[\"batch_size\"], 1), device = device)\n",
    "            \n",
    "            latent_space_samples = torch.randn((params[\"batch_size\"], 2), device = device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((params[\"batch_size\"], 1), device = device)\n",
    "            \n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "\n",
    "            # TRAINING DISCRIMINATOR\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            discriminator_loss = loss_function(output_discriminator, all_samples_labels)\n",
    "            discriminator_loss.backward()\n",
    "            discriminator_optimiser.step()\n",
    "\n",
    "\n",
    "            # DATA FOR GENERATOR\n",
    "            torch.manual_seed(RANDOM_SEED)\n",
    "            latent_space_samples = torch.randn((params[\"batch_size\"], 2), device = device)\n",
    "\n",
    "            # TRAINING GENERATOR\n",
    "            generator.zero_grad()\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            generator_loss = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            generator_loss.backward()\n",
    "            generator_optimiser.step()\n",
    "\n",
    "            if epoch % 10 == 0 and n == params[\"batch_size\"]:\n",
    "                print(f\"Epoch: {epoch} | G. Loss: {generator_loss} | D. Loss: {discriminator_loss}\")\n",
    "\n",
    "        # Pruning\n",
    "        # Need to create Pruner class for this particular case\n",
    "        # trial.report(generator_loss, epoch)\n",
    "        \n",
    "        # if trial.should_prune():\n",
    "        #    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    run_time = round(end_time - start_time, 2)\n",
    "    print(f\"Trial Complete!\\nRun time for this trial was {run_time} seconds.\\n\")\n",
    "\n",
    "    return generator_loss, discriminator_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235a5db-4dcf-4d0b-a145-bfb2b37701aa",
   "metadata": {},
   "source": [
    "## Objective function\n",
    "The aim of this function is to define a set of hyperparameter values, build the model, train the model, and evaluate the loss of both the generator and discriminator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4efa56d8-2e74-4375-aaeb-c6c1ebf8c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", low=1e-5, high=1e-1, log = True),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", low=8, high=64, step=8),\n",
    "        \"epochs\": trial.suggest_int(\"epochs\", low=10, high=100, step=10)\n",
    "    }\n",
    "\n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "\n",
    "    g_loss, d_loss = train_and_optimise(params, generator, discriminator, trial)\n",
    "\n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b441bf4-f807-4d7f-8186-3169bd427e8c",
   "metadata": {},
   "source": [
    "## Display all trials and best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20a71587-7270-4e35-9e7a-abcf7dd61751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all_trials(study):\n",
    "    df = study.trials_dataframe()\n",
    "    df = pd.DataFrame(df, columns = ['number', 'values_0', 'values_1', 'params_batch_size', 'params_epochs',\n",
    "                                          'params_learning_rate', 'state'])\n",
    "    df= df.rename(columns = {\"number\":\"Trial #\", \"values_0\":\"G Loss\", \"values_1\":\"D Loss\", \"params_batch_size\":\"Batch Size\", \n",
    "                     \"params_epochs\":\"Epochs\", \"params_learning_rate\":\"Learning Rate\", \"state\":\"State\"})\n",
    "    df[\"Trial #\"] += 1 # Adjust the trial numbers\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def display_best_trial(study):\n",
    "    best_trial = study.best_trials\n",
    "    best_trial_number = best_trial[0].number\n",
    "    best_trial_params = best_trial[0].params\n",
    "    best_trial_values = best_trial[0].values\n",
    "    print(\"~Best trial~\")\n",
    "    print(f\"Trial #: {best_trial_number}\")\n",
    "    print(f\"G Loss: {best_trial_values[0]}\\nD Loss: {best_trial_values[1]}\")\n",
    "    print(f\"Batch Size: {best_trial_params['batch_size']}\\nEpochs: {best_trial_params['epochs']}\\nLearning Rate: {best_trial_params['learning_rate']}\")\n",
    "\n",
    "def save_trials(study):\n",
    "    df = study.trials_dataframe()\n",
    "    now = str(datetime.now())\n",
    "    date, time = now.split(\" \")\n",
    "    time = time.replace(\":\",\".\")\n",
    "    df.to_csv(f\"Optimisation Trials/gan_optimisation_{date}_{time}.csv\", index = False)\n",
    "    print(f\"Trials saved to: gan_optimisation_{date}_{time}.csv\\n\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f0c69c1-f88c-44b4-82be-a259ae4495b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "     \n",
    "    return \"%d hours %02d mins %02d secs\" % (hour, minutes, seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbae1bc-d829-465e-92ef-0c3f0bf2d421",
   "metadata": {},
   "source": [
    "## Main program\n",
    "The study that is created provides a multi-objective optimisation, so that it can optimise more than one value - generator loss and discriminator loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f85c9b09-dc94-47a0-b1c3-c93af0d2c390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-04 18:01:24,992] A new study created in memory with name: GAN-Optimiser\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0abb4ae332486eb1d04391b6cc0487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | G. Loss: 3.39906644821167 | D. Loss: 50.029754638671875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e093d116528457a92212bffb463394a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f85140a977e4e9c8c739795a4c00414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58a58be5f1e44bf9d8fd0fd94116e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4b1675e4e2499b850d73d98e0583d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b19f817f1b04f63aae136add62d0452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e23b6e03e3d4c33b9f73e1777a2be7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e577be3d578b49c7bbe1cd9d88cf68b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5039951c13404c0296b3bd8c60e064fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d519d054344f3e9bb3becff93cbd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1b7037b1984457a90bcc5ff8d4820a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | G. Loss: 15.07404899597168 | D. Loss: 50.0000114440918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bba6f3e0d4c49b6aa2d9a4d6bda8c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efc223b21ad4eeca4d0343d69db0abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a44eba06fb45b884e7728155b95606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6571b98b74754fcc8b7301356849c53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce17057e28a4174ad5ffdcf756d0cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e845f71f801648929eaa12278035b8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a8aa85ec514a0d9302fbdb0ec6dd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9899c8cb00d4ee39762aa42984a75d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762a9571ddfc4cf99159a230153a3470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0410cd73870444b99a6a974d564ba6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | G. Loss: 16.876033782958984 | D. Loss: 50.00000762939453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0978d2ad9f487b8c3dcb067a972c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9c1886c2d34faeaeddf36282b97562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fc12ccadd540778a428fc7bfccc9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaf8d6bd915435dad99661e70e0d61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed7e88ef2cb4515998d1b4cc7461013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0e168b82fe4d3785c64a751a43443c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438ab87c97164be6bf5b22dd7abe4ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7b58da6a994cc9960f30f8aea545ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d73182be2ba495ba7a12de050e42d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf4ac3fb99941e283a4a0f02ae0ff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | G. Loss: 18.943466186523438 | D. Loss: 50.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e59eac57494c3c9b180f7ba05fd02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7224205800439dbe9d8340425edcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda3d98471ef415cb2d92e51e30b9135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfbd5677923495f95df4e151021ba45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd188804893e49f1bc377f899849b1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d41005b191245ec92774cf03589567a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23688eb7bc20455eb78022aed661350c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d28f3a94b740aab879c356108b6646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fea9c62d734fe38a1a025c2c1e3cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a2f2713ca04726834d3a4c994becdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | G. Loss: 20.17980194091797 | D. Loss: 50.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898fe5f998be427186602e301bd1c140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef179cf92be475b8eeb16a5023ed907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1c2bcfd102400b84ace953b1a33c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88720ff2c6024c099029483362bdecf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b2e82a9ba64aaca1aa5e301582a480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9da0e609e441afa63c04fd6fda7592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09594e574cbb49f284c0fadb368ff934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f612b6edd947e383419bddfb5d5ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2184f001f8824044a8dbe1e1db3a46c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-04 18:01:46,064] Trial 0 finished with values: [20.944059371948242, 50.0] and parameters: {'learning_rate': 0.0005944115431248001, 'batch_size': 24, 'epochs': 50}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Complete!\n",
      "Run time for this trial was 20.29 seconds.\n",
      "\n",
      "Optimsation complete!\n",
      "Optimisation run time was 0 hours 00 mins 21 secs\n",
      "\n",
      "Number of finished trials:  1\n",
      "Trials saved to: gan_optimisation_2024-01-04_18.01.46.092247.csv\n",
      "\n",
      "   Trial #     G Loss  D Loss  Batch Size  Epochs  Learning Rate     State\n",
      "0        1  20.944059    50.0          24      50       0.000594  COMPLETE\n",
      "\n",
      "\n",
      "~Best trial~\n",
      "Trial #: 0\n",
      "G Loss: 20.944059371948242\n",
      "D Loss: 50.0\n",
      "Batch Size: 24\n",
      "Epochs: 50\n",
      "Learning Rate: 0.0005944115431248001\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create the optimisation study\n",
    "    study = optuna.create_study(directions=[\"minimize\", \"minimize\"], study_name = \"GAN-Optimiser\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "    # Optimise the objective function\n",
    "    start_time = time.time()\n",
    "    study.optimize(objective, n_trials = 1) # Number of trials to test with different values\n",
    "    end_time = time.time()\n",
    "\n",
    "    optimisation_run_time = convert_time(round(end_time - start_time, 2))\n",
    "    \n",
    "    print(f\"Optimsation complete!\\nOptimisation run time was {optimisation_run_time}\\n\")\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    save_trials(study)\n",
    "    display_all_trials(study)\n",
    "    display_best_trial(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
